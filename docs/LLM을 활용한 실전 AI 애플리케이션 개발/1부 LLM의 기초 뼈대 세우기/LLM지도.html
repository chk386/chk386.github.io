<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-LLM을 활용한 실전 AI 애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM지도" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">LLM지도 | 아윤아 사랑해. 만화 그만봐</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://cdn.outsideonline.com/wp-content/uploads/2021/06/15/camping_fun_h.jpg"><meta data-rh="true" name="twitter:image" content="https://cdn.outsideonline.com/wp-content/uploads/2021/06/15/camping_fun_h.jpg"><meta data-rh="true" property="og:url" content="https://chk386.github.io/docs/LLM을 활용한 실전 AI 애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM지도"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="LLM지도 | 아윤아 사랑해. 만화 그만봐"><meta data-rh="true" name="description" content="LLM이란?"><meta data-rh="true" property="og:description" content="LLM이란?"><link data-rh="true" rel="icon" href="/img/favicon/favicon.ico"><link data-rh="true" rel="canonical" href="https://chk386.github.io/docs/LLM을 활용한 실전 AI 애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM지도"><link data-rh="true" rel="alternate" href="https://chk386.github.io/docs/LLM을 활용한 실전 AI 애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM지도" hreflang="en"><link data-rh="true" rel="alternate" href="https://chk386.github.io/docs/LLM을 활용한 실전 AI 애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM지도" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="아윤아 사랑해. 만화 그만봐 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="아윤아 사랑해. 만화 그만봐 Atom Feed">



<link rel="alternate" type="application/rss+xml" href="/blog2/rss.xml" title="아윤아 사랑해. 만화 그만봐 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog2/atom.xml" title="아윤아 사랑해. 만화 그만봐 Atom Feed"><link rel="stylesheet" href="/assets/css/styles.a32ba54b.css">
<script src="/assets/js/runtime~main.b723aae1.js" defer="defer"></script>
<script src="/assets/js/main.0f099a95.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Q_QoV</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/LLM을 활용한 실전 AI 애플리케이션 개발">기술문서</a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/blog">블로그</a><a href="https://github.com/chk386/chk386.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item pink"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" href="/docs/LLM을 활용한 실전 AI 애플리케이션 개발">LLM을 활용한 실전 AI 애플리케이션 개발</a><button aria-label="Collapse sidebar category &#x27;LLM을 활용한 실전 AI 애플리케이션 개발&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/LLM을 활용한 실전 AI   애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM지도">1부 LLM의 기초 뼈대 세우기</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item pink"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/LLM을 활용한 실전 AI 애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM지도">LLM지도</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item pink"><a class="menu__link" tabindex="0" href="/docs/LLM을 활용한 실전 AI 애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM의 중추, 트랜스포머 아키텍처 살펴보기">LLM의 중추, 트랜스포머 아키텍처 살펴보기</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/안다르">frontend</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">intro</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/LLM을 활용한 실전 AI 애플리케이션 개발"><span itemprop="name">LLM을 활용한 실전 AI 애플리케이션 개발</span></a><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">1부 LLM의 기초 뼈대 세우기</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">LLM지도</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>LLM지도</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="llm이란">LLM이란?<a href="#llm이란" class="hash-link" aria-label="Direct link to LLM이란?" title="Direct link to LLM이란?">​</a></h2>
<ul>
<li>대규모 언어 모델(Large Language Model)은 수많은 파라미터(수십억 wight)를 보유한 인공 신경망으로 구성 되는 언어 모델</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3가지-작동-방식">3가지 작동 방식<a href="#3가지-작동-방식" class="hash-link" aria-label="Direct link to 3가지 작동 방식" title="Direct link to 3가지 작동 방식">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="토큰화">토큰화<a href="#토큰화" class="hash-link" aria-label="Direct link to 토큰화" title="Direct link to 토큰화">​</a></h3>
<p>일반 인간 언어를 이해할 수 있는 시퀀스로 변화하는 작업을 의미(인코딩 작업), 문장 구조 예측하기 위한 학습 가이트 또는 공식과 같은 컨 텍스트 백터 생성이 목적</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="트랜스포머-모델">트랜스포머 모델<a href="#트랜스포머-모델" class="hash-link" aria-label="Direct link to 트랜스포머 모델" title="Direct link to 트랜스포머 모델">​</a></h3>
<p>순차적 데이터를 검사하여 어떤 단어가 서로 뒤따를 가능성이 높은지 관련 패턴을 식별하는 신경망의 일종으로 각각 다른 분석을 수행하여 어떤 단어가 호환되는지 결정하는 계층으로 구성된다. 이러한 모델은 언어를 학습하지 않고 알고리즘에 의존하여 사람이 쓴 단어를 이해하고 예를 들어, 힙스터 커피 블로그를 제공함으로써 커피에 대한 표준 글을 작성하도록 학습시킨다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="프롬프트">프롬프트<a href="#프롬프트" class="hash-link" aria-label="Direct link to 프롬프트" title="Direct link to 프롬프트">​</a></h3>
<p>개발자가 정보를 분석하고 토큰화하기 위해 대규모 언어 모델 LLM에 제공하는 정보로 프롬프트는 기본적으로 다양한 사용 사례에서 LLM에 도움이 되는 학습 데이터이다. 더 정확한 프롬프트를 받을수록 LLM은 다음 단어를 더 잘 예측하고 정확한 문장을 구성할 수 있다. 따라서 딥러닝 AI의 적절한 학습을 위해서는 적절한 프롬프트를 선택하는 것이 중요하다.</p>
<p><img decoding="async" loading="lazy" src="https://private-user-images.githubusercontent.com/6337404/375949265-0710ca7a-7074-42e6-a070-22bd8e3efb80.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjg3Mjc3NDcsIm5iZiI6MTcyODcyNzQ0NywicGF0aCI6Ii82MzM3NDA0LzM3NTk0OTI2NS0wNzEwY2E3YS03MDc0LTQyZTYtYTA3MC0yMmJkOGUzZWZiODAuanBnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTAxMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEwMTJUMTAwNDA3WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZmFjZGZiNzQyOWRlOGEwYzVmMGVkZWYzYjk5ZTVhNmRkMDA0YjFmMzM0ZDk2NDc1OGMzOTI2ZTc0NWVlYzc0YiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.StcQ2p4XqQ3YJAjAnjemPvrrB-scINTTlFw7eODJyTA" alt="작동방식" class="img_ev3q"></p>
<p><a href="https://blog.naver.com/showtech00/223235508879" target="_blank" rel="noopener noreferrer">source</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rag-이란">RAG 이란?<a href="#rag-이란" class="hash-link" aria-label="Direct link to RAG 이란?" title="Direct link to RAG 이란?">​</a></h2>
<ul>
<li>검색 증강 생성</li>
<li>기업 내부의 다양한 문서와 데이터를 임베딩이라는 기술을 활용해 벡터 데이터베이스로 지식 기반을 구축한 다음에 사용자가 질문하는 대답과 가장 관련이 있는 문서 조각을 지식 기반으로부터 뽑아내 LLM에게 요약 정리하게 만드는 방법으로 동작하는 애플리케이션을 의미한다.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="ai와-llm-시장-키워드">AI와 LLM 시장 키워드<a href="#ai와-llm-시장-키워드" class="hash-link" aria-label="Direct link to AI와 LLM 시장 키워드" title="Direct link to AI와 LLM 시장 키워드">​</a></h2>
<ul>
<li><code>Multi Modal</code> : 텍스트뿐 아니라 이미지, 음성, 동영상등 다양한 데이터 처리<!-- -->
<ul>
<li>OpenAI의 GPT-4o, Google의 Astra, Anthropic의 클로드 3.5 Sonnet</li>
</ul>
</li>
<li><code>Agent</code>: 인터넷 검색, 코드 실행, 오피스와 같은 다양항 도구를 활용해 문제 해결하는 발전된 시스템<!-- -->
<ul>
<li>MS Copilot Agent</li>
</ul>
</li>
<li><code>On-Device AI</code> : 사용자 장비에서 실행, 정보 유출 해결<!-- -->
<ul>
<li>Apple Intelligence, 네이밍 센스</li>
</ul>
</li>
</ul>
<h1>1부 LLM 기초 뼈대 세우기</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-llm-지도">1. LLM 지도<a href="#1-llm-지도" class="hash-link" aria-label="Direct link to 1. LLM 지도" title="Direct link to 1. LLM 지도">​</a></h2>
<p>ChatGPT는 굉장히 단순한 과정으로 동작한다. 주어진 입력에서 다음에 올 적잘한 단어를 확률적으로 선택(예측, 언어모델이라고 함)하고, 선택한 단어를 입력에 더해 문장이 끝날 때까지 선택하는 작업을 반복한다.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="딥러닝과-언어-모델링">딥러닝과 언어 모델링<a href="#딥러닝과-언어-모델링" class="hash-link" aria-label="Direct link to 딥러닝과 언어 모델링" title="Direct link to 딥러닝과 언어 모델링">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FNElGV%2FbtsH9K1cPN9%2Fb2F7dMHsmXBllCZPkICBX1%2Fimg.png" alt="인공지능 분류" class="img_ev3q"></p>
<p><a href="https://ictexpert.tistory.com/53" target="_blank" rel="noopener noreferrer">출처</a></p>
<ul>
<li>LLM은 기술적으로 딥러닝 기반</li>
<li>Deep Learning이란 인간 두뇌에 영감을 받아 만들어진 neural network로서 데이터 패턴을 학습하는 머신러닝(기계학습)의 한 분야</li>
<li>표 형태의 정형 데이터뿐 아니라 텍스트, 이미지와 같은 비정형 데이터(unstructured data)에서도 뛰어난 패턴 인식 성능을 보임</li>
<li>LLM은 사람의 언어를 컴퓨터가 이해하고 생성할 수 있도록 연구하는 자연어 처리(natural language processing)분야에 속함</li>
<li>특히 사람과 비슷하게 텍스트를 생성하는 방법을 연구하는 <code>자연어 생성(natural language generation)</code>이 LLM임</li>
<li>즉 LLM은 <code>딥러닝 기반의 언어 모델</code></li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="데이터-특징을-스스로-추출하는-딥러닝">데이터 특징을 스스로 추출하는 딥러닝<a href="#데이터-특징을-스스로-추출하는-딥러닝" class="hash-link" aria-label="Direct link to 데이터 특징을 스스로 추출하는 딥러닝" title="Direct link to 데이터 특징을 스스로 추출하는 딥러닝">​</a></h4>
<ul>
<li>2012년 이미지 인식 대회인 이미지넷에서 딥러닝 모델인 알렉스넷이 우승</li>
<li>전년도 오류율 26%, 알렉스넷은 16%로 오류율로 충격을 줌</li>
<li>혁신적인 문제 해결 접근 방식<!-- -->
<ol>
<li>문제의 유형(이미지, 텍스트)에 따라 일반적으로 사용되는 모델 준비</li>
<li>풀고자 하는 문제에 대한 학습 데이터 준비</li>
<li>학습 데이터를 반복적으로 모델이 입력</li>
</ol>
</li>
<li>이렇게 3단계만 거치면 문제 해결됨</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbdGJrO%2FbtrgimAtbnD%2FCzCgYarRcAeZ1KkIgxQDBK%2Fimg.png" alt="deepVSmachine" class="img_ev3q">
<a href="https://wooono.tistory.com/m/206" target="_blank" rel="noopener noreferrer">SOURCE</a></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="임베딩">임베딩<a href="#임베딩" class="hash-link" aria-label="Direct link to 임베딩" title="Direct link to 임베딩">​</a></h4>
<ul>
<li>딥러닝 모델은 데이터의 특징을 추출하는 방법도 함께 학습함</li>
<li>데이터의 의미를 숫자의 집합으로 표현함</li>
<li>책에서는 MBTI를 예를 들어 설명함<!-- -->
<ul>
<li>세명의 사람이 각각 ENTP(0.7, 0.3, 0.8, 0.1) INTP(0.3, 0.2, 0.9, 0.2) ESFJ(0.8, 0.8, 0.2, 0.6) 숫자로 표현한다면 거리를 계산하여 유사도를 얻을 수 있음</li>
</ul>
</li>
<li>거리를 계산할 수 있기에<!-- -->
<ol>
<li>검색어와 관련이 있는 상품을 추천 가능해짐</li>
<li>클러스터링 및 분류 : 유사하고 관련이 있는 데이터를 하나로 묶을수 있음</li>
<li>이상치(outlier)탐지 : 범위가 많이 벗어난 이상치를 탐지 할수 있음</li>
</ol>
</li>
<li>데이터를 숫자로 변환하는 법 : <a href="https://arxiv.org/pdf/1411.2738" target="_blank" rel="noopener noreferrer">word2vec</a></li>
<li>단어를 word2vec 모델을 통해 숫자의 집합인 임베딩으로 변환함(word embedding)</li>
<li>단어 -&gt; word2vec -&gt; 0.1, 0.7, ...., 0.3</li>
<li>숫자 하나하나의 의미를 인간이 이해할수 없음. 숫자 집합 전체는 단어의 의미를 담고 있다는 사실은 인지 가능</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="언어-모델링">언어 모델링<a href="#언어-모델링" class="hash-link" aria-label="Direct link to 언어 모델링" title="Direct link to 언어 모델링">​</a></h4>
<ul>
<li>딥러닝 분야에서는 하나의 문제를 해결하는 과정에서 얻은 지식과 정보를 다른 문제를 풀 때 사용하는 방식을 많이 활용함. <code>전이 학습(transfer learning)</code></li>
<li>대량의 데이터로 모델을 학습시키는 <code>사전학습</code>과특정한 문제를 해결하기 위한 데이터로 추가 학습하는 <code>미세 조정(fine-tuning)</code> 두 단계로 나눠 학습을 진행</li>
<li>자연어 처리보다 먼저  <code>이미지 인식 분야</code>에서는 이미 학습된 모델을 필요한 과제에 맞춰 추가로 학습하는 전이 학습 개념이 널리 활용중이였음<!-- -->
<ul>
<li><img decoding="async" loading="lazy" alt="그림 1.8" src="/assets/images/1.8-83ca7893fa266b85d8327b95f8514110.jpg" width="2537" height="1659" class="img_ev3q"></li>
<li>유방암이 양성인지 분류한는 문제를 풀때 유방암 데이터보다 사전 학습 모델을 활용했을때 성능이 더 높음</li>
<li>사전 학습에 사용한 이미지가 현재 풀고자 하는 과제와 다르더라도 선이나 점 같은 특징을 파악하는 능력은 공통적으로 필요함</li>
<li>이떄 사전 학습 모델을 미세 조정해 풀고자 하는 과제를 <code>다운스트림(downstream)</code>과제라고 부름</li>
<li>더 적은 유방암 이미지만으로 높은 성능의 모델을 학습 시킬 수 있음</li>
<li>머신러닝은 처음부터 끝까지 해결하려는 문제의 데이터로 학습하는 방식이나 딥러닝의 전이 합ㄱ습은 대량의 데이터 학습(사전 학습)과 현재 해결하려는 문제의 데이터로 추가 학습(미세조정)하는 두 단계로 모델을 학습시킴</li>
</ul>
</li>
<li>아래 그림은 기존 지도 학습과 다르게 모델 본체는 대규모 데이터셋인 이미지넷으로 학습한 모델에서 가져오고 분류를 수행하는 헤드 부분은 해결하려는 작업의 데이터셋으로 추가 학습함<!-- -->
<ul>
<li><img decoding="async" loading="lazy" alt="그림 1.9" src="/assets/images/1.9-c4f1e8d67dca31066c04bd9233bdd4ac.jpg" width="2095" height="1543" class="img_ev3q"></li>
<li>헤드를 추가 학습하는 과정이 사전 학습에 비해 적은 양의 학습 데이터를 사용한다는 의미에서 <code>미세 조정(fine-tuning)</code>이라 불림</li>
</ul>
</li>
<li>자연어 처리 분야의 전이학습<!-- -->
<ul>
<li>2018년 fast.ai에서 다음 단어를 예측하는 언어 모델링 방식으로 사전 학습을 수행했을 때 훨씬 적은 레이블 데이터로도 기존 지도 학습 모델의 성능을 뛰어 넘는 사실을 발견</li>
<li><code>트랜스포머 아키텍처</code></li>
<li><a href="https://arxiv.org/pdf/1801.06146" target="_blank" rel="noopener noreferrer">Universal Language Model Fine-tuning for Text Classification</a></li>
<li>텍스트 데이터 레이블 없이 다음 단어 예측 방식으로 사전 학습에 활용할 수 있는 길이 열림</li>
<li>순환신경망(RNN)에서 모델링 사전 학습 과제로 적합하다는 사실 확인</li>
<li>Google의 BERT, OpenAI GPT-1</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="언어-모델이-chat-gpt가-되기까지">언어 모델이 chat gpt가 되기까지<a href="#언어-모델이-chat-gpt가-되기까지" class="hash-link" aria-label="Direct link to 언어 모델이 chat gpt가 되기까지" title="Direct link to 언어 모델이 chat gpt가 되기까지">​</a></h3>
<p>2017 : 트랜스포머
2018 : GPT-1
2019 : GPT-2
2020 : GPT-3
2022 : ChatGPT
2024 : GPT-4o</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="rnn---트랜스포머-아키텍처">RNN -&gt; 트랜스포머 아키텍처<a href="#rnn---트랜스포머-아키텍처" class="hash-link" aria-label="Direct link to RNN -&gt; 트랜스포머 아키텍처" title="Direct link to RNN -&gt; 트랜스포머 아키텍처">​</a></h4>
<ul>
<li>
<p>텍스트는 단어가 연결된 문장 형태의 데이터를 말함</p>
</li>
<li>
<p>작은 단위(단어)의 데이터가 연결되고 길이가 다양한 데이터 형태를 <code>시퀀스</code></p>
</li>
<li>
<p>시퀀스 데이터 처리를 위해 RNN과 트랜스포머로 대표되는 다양한 모델 사용</p>
</li>
<li>
<p>순환신경망 (RNN)</p>
<ul>
<li>이전 데이터를 기억, 다음 데이터의 입력으로 넣어 출력에 영향을 줄 수 있는 네트워크 구조</li>
<li>시퀀스(문장)이나 연속적인 시계열 데이터에 사용</li>
<li>특징<!-- -->
<ul>
<li>모델이 간단</li>
<li>큰 시퀀스 데이터도 처리 가능</li>
<li>이전 정보 반영 : 아윤이가 포크를 들고 돈까스를 먹었다. -&gt; 아윤이가 + 포크를 + 들고 + 돈까스를 이라는 이전 정보를 통해 <code>먹었다</code>를 예측 할수 있음.</li>
<li><code>아윤이</code>와 <code>먹었다</code> 처럼 노드 위치가 먼 상태일 경우 문맥 처리가 힘듬</li>
<li>먼저 입력한 단어가 점차 회석됨</li>
<li>여러 단어로 구성된 맥락을 하나의 잠재 상태에 압축하기에 메모리 적게 사용</li>
<li>다음 단어 예측시 지금까지 계산을 통해 만들어진 잠재 상태와 입력 단어만 있으면 되기 때문에 다음 단어 빠르게 생성</li>
<li><img decoding="async" loading="lazy" alt="1.12" src="/assets/images/1.12-3e2cde7e69ce17319bfd2740499182ff.png" width="1905" height="832" class="img_ev3q"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>트랜스포머 아키텍처</p>
<ul>
<li>2017년 등장</li>
<li>순차처리 방식 버림</li>
<li>맥락을 모두 참조하는 어텐션(attention)연산을 사용하여 문제 대부분 해결</li>
<li>맥락 데이터 그대로 모두 활용하여 다음 단어 예측</li>
<li>아래와 같이 맥락을 압축하지 않고 그대로 활용하기 때문에 성능을 높일 수 있지만 메모리 사용량이 증가</li>
<li>입력이 길면 시간도 증가, 많은 연산량이 필요하지만 순차적인 RNN과 달리 병렬 처리가 가능</li>
<li>현재 대부분의 LLM은 트랜스포터 아키텍처 기반임</li>
</ul>
</li>
</ul>
<!-- -->
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="gpt시리즈로-살펴보는-모델-크기성능-관계">GPT시리즈로 살펴보는 모델 크기&amp;성능 관계<a href="#gpt시리즈로-살펴보는-모델-크기성능-관계" class="hash-link" aria-label="Direct link to GPT시리즈로 살펴보는 모델 크기&amp;성능 관계" title="Direct link to GPT시리즈로 살펴보는 모델 크기&amp;성능 관계">​</a></h4>
<table><thead><tr><th>Release Date</th><th>Version</th><th>Parameter Count</th><th>-</th></tr></thead><tbody><tr><td>2018.06.11</td><td>GPT-1</td><td>1.17억</td><td></td></tr><tr><td>2019.02.14</td><td>GPT-2</td><td>15억</td><td></td></tr><tr><td>2020.06.11</td><td>GPT-3</td><td>1,750억</td><td>인간 언어 생성 능력과 유사</td></tr></tbody></table>
<p>OpenAI의 GPT는 모델 구조 큰 변경 없이 오직 모델과 학습 데이터셋의 크기만 키웠음. 이렇게 간단한 접근 방식으로 언어 모델 성능이 크게 높아짐.</p>
<p>학습 데이터와 언어 모델의 결과가 모두 <code>생성된 언어</code>이며 따라서 언어 모델이 학습하는 과정을 학습 데이터를 압축하는 과정으로 생각할 수 있다.
무손실 압축이 아니라 중요 패턴을 남기는 손실 압축이며 Meta의 라마2 의 경우 약 10TB 텍스트로 학습해 최종적으로 140GB 크기의 모델이 된다. 학습 데이터 대비 <code>약 1.4%</code>정도의 작은 모델에, 학습 데이터가 갖고 있던 텍스트 생성의 패턴을 압축하였다.</p>
<p><img decoding="async" loading="lazy" alt="Meta-Liama2" src="/assets/images/1.18-2e2bfe11747d7eec6742db8396988404.png" width="1939" height="817" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="chatgpt-두둥등장">ChatGPT 두둥등장<a href="#chatgpt-두둥등장" class="hash-link" aria-label="Direct link to ChatGPT 두둥등장" title="Direct link to ChatGPT 두둥등장">​</a></h4>
<ul>
<li>
<p>GTP-3는 사용자의 말을 이어서 작성하는 능력밖에 없었음</p>
</li>
<li>
<p>ChatGPT는 <code>지도미세조정(supervised fine-tuning)과 RLHF(Reinforcement Learning from Human Feedback, 사람의 피드백을 활용한 강화 학습)</code>라는 기술을 <a href="https://arxiv.org/pdf/2203.02155" target="_blank" rel="noopener noreferrer">논문</a>으로 발표</p>
</li>
<li>
<p>위 기술들을 통해 다음에 이어질 텍스트 생성이 아니라 사용자의 요청을 해결할 수 있는 텍스트 생성이 가능해짐</p>
</li>
<li>
<p>생성하는 답변을 사용자 요청 의도에 맞추는 것을 <code>정렬(alignment)</code>라고 함</p>
</li>
<li>
<p><code>지도 미세 조정</code>은 정렬을 위한 핵심적인 학습 과정이며 언어 모델링으로 사전 학습한 언어 모델을 <code>지시 데이터셋(instruction dataset)</code>으로 추가 학습하는 것을 뜻함. 지시 데이터셋은 사용자가 요청 또는 지시한 사항과 그에 대한 적절한 응답을 정리한 데이터셋을 의미 -&gt; 수많은 데이터 작업자를 고용해 LLM이 받을 법한 질문과 그에 대한 답변을 작성하게 했으며 이를 활용 지도 미세 조정을 수행함.</p>
</li>
<li>
<p>사용자가 요청에 응답하는것이 항상 옳은가? -&gt; 윤리적 문제</p>
</li>
<li>
<p>정확한 답변이라도 사용자가 더 쉽게 생성해준다거나 인종, 성별등 차별적 표현을 사용하지 않게 노력해야함</p>
</li>
<li>
<p>OpenAI에서는 두 가지 답변 중 사용자가 더 선호 하는 답변을 선택한 데이터셋(<code>선호 데이터셋</code>)을 구축 하였음. 이 선호 데이터셋으로 LLM의 답변을 평가하는 <code>리워드 모델(reward model)</code>을 만들고 LLM이 점점 더 높은 점수를 받을 수 있도록 추가 학습을 하는데, 이떄 <code>강화 학습(reinforcement learning)</code>을 사용하기 때문에 이 기술을 RLHF(사람의 피드백을 활용한 강화 학습)이라 부른다.</p>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="llm-application-시대">LLM Application 시대<a href="#llm-application-시대" class="hash-link" aria-label="Direct link to LLM Application 시대" title="Direct link to LLM Application 시대">​</a></h4>
<ul>
<li>ChatGPT의 충격은 많은 기업, 조직에서 LLM을 활용한 애플리케이션을 개발하기 위해 노력중</li>
<li>LLM이 큰 영향을 미치는 이유는 <code>다재다능함</code> 때문임</li>
<li>대부분의 지식 노동자가 수행하는 작업은 언어의 이해와 생성을 모두 포함하기에 자동화가 어려웠으나 LLM은 자연어 이해와 생성 성능이 모두 뛰어남</li>
<li><code>비교적 간단한 작업</code>에서 사람을 완전히 대체할 수 있어 많은 기대와 우려가 동시에 받고 있음</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="sllm-더-작고-효율적인-모델-만들기">sLLM 더 작고 효율적인 모델 만들기<a href="#sllm-더-작고-효율적인-모델-만들기" class="hash-link" aria-label="Direct link to sLLM 더 작고 효율적인 모델 만들기" title="Direct link to sLLM 더 작고 효율적인 모델 만들기">​</a></h4>
<p>LLM 애플리케이션 개발 하는 2가지 방법</p>
<ol>
<li>OpenAI의 GPT-4나 구글 제미나이와 같은 상업용 API를 사용</li>
<li>오픈소스 LLM을 활용해 직접 LLM API를 생성해 사용하는 방법</li>
</ol>
<ul>
<li>상업용이 모델이 크고 범용 텍스트 생성 능력이 뛰어나지만 원하는 도메인의   데이터, 작업을 위한 데이터로 자유롭게 추가 학습할 수 있는 오픈소스 LLM의 장점도 있다.</li>
<li>추가 학습을 하는 경우 모델 크기가 작으면서도 특정 도메인에서 높은 성능을 보이는 모델을 만들 수 있으며 이를 <code>sLLM(small Large Language Model)</code>이라 함.</li>
<li>대표적으로 2024년 4월 메타의 라마-3, MS의 Phi-3를 오픈소스로 공개하였음.</li>
<li>특히 Phi-3 미니 모델은 38억개의 적은 파라미터로 강력한 언어 추론 능력을 보여주었음. 개선해야 될 점들이 남아있으나, 모바일 기기에서 chatGPT 무료 버전 수준의 서비스를 제공할 수 있다는 가능성을 보여줌.</li>
<li>텍스트 요청을 SQL로 변환하는 작업에서 GPT-4를 뛰어넘은 Defog.ai의 SQLCoder도 sLLM임.</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="환각-현상에-대처하는-검색-증강-생성rag">환각 현상에 대처하는 검색 증강 생성(RAG)<a href="#환각-현상에-대처하는-검색-증강-생성rag" class="hash-link" aria-label="Direct link to 환각 현상에 대처하는 검색 증강 생성(RAG)" title="Direct link to 환각 현상에 대처하는 검색 증강 생성(RAG)">​</a></h4>
<ul>
<li><code>환각 현상</code>이란 잘못된 정보나 실제로 존재하지 않는 정보-를 만들어 내는 현상</li>
<li>정확한 이유는 알기 어렵지만 기본적으로 학습 데이터를 손실 압축해 그럴듯한 문장을 만들 뿐 어떤 정보가 사실인지, 거짓인지 학습한 적은 없어 특정 정보가 사실인지 판단할 능력이 없음</li>
<li>또한 압축하는 과정에서 비교적 드물게 등장하는 정보는 소실될 수 있으며 이런 영향으로 부정확한 정보를 생성하는 원인이 될 수도 있음</li>
<li>이런 문제를 줄이기 위해 RAG 기술 사용, 프롬프트에 LLM이 답변할때 필요한 정보를 미리 추가함으로써 문제를 줄임</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="llm의-미래">LLM의 미래<a href="#llm의-미래" class="hash-link" aria-label="Direct link to LLM의 미래" title="Direct link to LLM의 미래">​</a></h3>
<ul>
<li>큰 세가지 흐름<!-- -->
<ol>
<li>더 다양한 형식의 데이터(이미지, 비디오, 오디오 등)을 입력, 출력도 여러 행태로 발전된 <code>멀티 모달</code></li>
<li>텍스트 생성 능력을 사용해 계획을 세우거나 의사결정을 내리고 필요한 행동까지 수행하는 <code>에이전트</code></li>
<li>트랜스포머 아키텍처를 <code>새로운 아키텍처</code>로 변경하여 더 긴 입력을 효율적으로 처리하는 연구</li>
</ol>
</li>
</ul>
<p><strong>지금의 LLM연구는 최첨단 LLM과 비교적 작은 sLLM으로 크게 분기되어 발전중</strong></p>
</div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/LLM을 활용한 실전 AI 애플리케이션 개발"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">LLM을 활용한 실전 AI 애플리케이션 개발</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/LLM을 활용한 실전 AI 애플리케이션 개발/1부 LLM의 기초 뼈대 세우기/LLM의 중추, 트랜스포머 아키텍처 살펴보기"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">LLM의 중추, 트랜스포머 아키텍처 살펴보기</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#llm이란" class="table-of-contents__link toc-highlight">LLM이란?</a></li><li><a href="#3가지-작동-방식" class="table-of-contents__link toc-highlight">3가지 작동 방식</a><ul><li><a href="#토큰화" class="table-of-contents__link toc-highlight">토큰화</a></li><li><a href="#트  랜스포머-모델" class="table-of-contents__link toc-highlight">트랜스포머 모델</a></li><li><a href="#프롬프트" class="table-of-contents__link toc-highlight">프롬프트</a></li></ul></li><li><a href="#rag-이란" class="table-of-contents__link toc-highlight">RAG 이란?</a></li><li><a href="#ai와-llm-시장-키워드" class="table-of-contents__link toc-highlight">AI와 LLM 시장 키워드</a></li><li><a href="#1-llm-지도" class="table-of-contents__link toc-highlight">1. LLM 지도</a><ul><li><a href="#딥러닝과-언어-모델링" class="table-of-contents__link toc-highlight">딥러닝과 언어 모델링</a></li><li><a href="#언어-모델이-chat-gpt가-되기까지" class="table-of-contents__link toc-highlight">언어 모델이 chat gpt가 되기까지</a></li><li><a href="#llm의-미래" class="table-of-contents__link toc-highlight">LLM의 미래</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">기술 Wiki</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 QQoV. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>